{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e45bea-a141-48e9-b03b-a10b36f78e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06d2eeea7224c77b4fe794f616d2978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daudr\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\daudr\\.cache\\huggingface\\hub\\models--google--flan-t5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597927d3e77441a98c5f3156512df63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d56e69f8a3c4feca0bf4faa3f1b641f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5031ca98c0c41548e8f565af52c6db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a112343c508401f879f469fe7f96baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc11f4fcab334c33812ccc8b18e2d322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e39adba3ac4bfa85186eaf99e46b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Auto Tagging Support Tickets Using LLM\n",
      "============================================================\n",
      "\n",
      "Ticket: I can't log in to my account. It says invalid credentials.\n",
      "True Tag: login_issue\n",
      "Zero-shot Top-3: ['login_issue', 'account_update', 'password_reset']\n",
      "Few-shot Top-3:  ['login_issue', 'account_update', 'password_reset']\n",
      "\n",
      "Ticket: The app crashes every time I open the settings menu.\n",
      "True Tag: app_crash\n",
      "Zero-shot Top-3: ['app_crash', '2fa_issue', 'ui_bug']\n",
      "Few-shot Top-3:  ['app_crash', '2fa_issue', 'login_issue']\n",
      "\n",
      "Ticket: How do I reset my password? I forgot it.\n",
      "True Tag: password_reset\n",
      "Zero-shot Top-3: ['password_reset', 'login_issue', 'account_update']\n",
      "Few-shot Top-3:  ['password_reset', 'login_issue', 'account_update']\n",
      "\n",
      "Ticket: Payment failed even though my card is valid.\n",
      "True Tag: payment_issue\n",
      "Zero-shot Top-3: ['payment_issue', 'billing_dispute', '2fa_issue']\n",
      "Few-shot Top-3:  ['payment_issue', 'billing_dispute', '2fa_issue']\n",
      "\n",
      "Ticket: The search feature returns irrelevant results.\n",
      "True Tag: search_issue\n",
      "Zero-shot Top-3: ['search_issue', '2fa_issue', 'ui_bug']\n",
      "Few-shot Top-3:  ['search_issue', 'app_crash', 'notification_issue']\n",
      "\n",
      "Ticket: I need to update my billing address.\n",
      "True Tag: account_update\n",
      "Zero-shot Top-3: ['account_update', 'billing_dispute', '2fa_issue']\n",
      "Few-shot Top-3:  ['account_update', 'billing_dispute', '2fa_issue']\n",
      "\n",
      "Ticket: The download button does nothing when clicked.\n",
      "True Tag: ui_bug\n",
      "Zero-shot Top-3: ['ui_bug', '2fa_issue', 'app_crash']\n",
      "Few-shot Top-3:  ['ui_bug', '2fa_issue', 'app_crash']\n",
      "\n",
      "Ticket: Email notifications are not being sent.\n",
      "True Tag: notification_issue\n",
      "Zero-shot Top-3: ['notification_issue', 'password_reset', 'login_issue']\n",
      "Few-shot Top-3:  ['notification_issue', 'search_issue', 'login_issue']\n",
      "\n",
      "Ticket: Two-factor authentication is not working.\n",
      "True Tag: 2fa_issue\n",
      "Zero-shot Top-3: ['2fa_issue', 'login_issue', 'password_reset']\n",
      "Few-shot Top-3:  ['2fa_issue', 'billing_dispute', 'search_issue']\n",
      "\n",
      "Ticket: I was charged twice for the same subscription.\n",
      "True Tag: billing_dispute\n",
      "Zero-shot Top-3: ['billing_dispute', 'payment_issue', '2fa_issue']\n",
      "Few-shot Top-3:  ['billing_dispute', '2fa_issue', 'payment_issue']\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š PERFORMANCE COMPARISON\n",
      "Zero-shot Top-3 Accuracy: 100.00%\n",
      "Few-shot Top-3 Accuracy:  100.00%\n",
      "\n",
      "============================================================\n",
      "ðŸ’¡ Fine-tuning is not implemented in this script.\n",
      "To implement fine-tuning:\n",
      "  1. Prepare dataset in 'input: ticket, target: tag' format\n",
      "  2. Use Hugging Face Trainer with Seq2SeqTrainingArguments\n",
      "  3. Train model and replace inference model above\n",
      "Example fine-tuning guide: https://huggingface.co/docs/transformers/training\n",
      "\n",
      "âœ… Done.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "\n",
    "#CONFIG & HYPERPARAMETERS\n",
    "MODEL_NAME = \"google/flan-t5-large\"  #You can switch to \"t5-small\" for faster testing\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MAX_LENGTH = 512\n",
    "NUM_BEAMS = 4\n",
    "TOP_K = 50\n",
    "TOP_P = 0.95\n",
    "\n",
    "#Simulated dataset (replace with your real dataset)\n",
    "SUPPORT_TICKETS = [\n",
    "    {\"text\": \"I can't log in to my account. It says invalid credentials.\", \"true_tag\": \"login_issue\"},\n",
    "    {\"text\": \"The app crashes every time I open the settings menu.\", \"true_tag\": \"app_crash\"},\n",
    "    {\"text\": \"How do I reset my password? I forgot it.\", \"true_tag\": \"password_reset\"},\n",
    "    {\"text\": \"Payment failed even though my card is valid.\", \"true_tag\": \"payment_issue\"},\n",
    "    {\"text\": \"The search feature returns irrelevant results.\", \"true_tag\": \"search_issue\"},\n",
    "    {\"text\": \"I need to update my billing address.\", \"true_tag\": \"account_update\"},\n",
    "    {\"text\": \"The download button does nothing when clicked.\", \"true_tag\": \"ui_bug\"},\n",
    "    {\"text\": \"Email notifications are not being sent.\", \"true_tag\": \"notification_issue\"},\n",
    "    {\"text\": \"Two-factor authentication is not working.\", \"true_tag\": \"2fa_issue\"},\n",
    "    {\"text\": \"I was charged twice for the same subscription.\", \"true_tag\": \"billing_dispute\"},\n",
    "]\n",
    "\n",
    "#Define all possible tags\n",
    "ALL_TAGS = sorted(list(set(ticket[\"true_tag\"] for ticket in SUPPORT_TICKETS)))\n",
    "\n",
    "#Few-shot examples (for demonstration â€” pick 3 random)\n",
    "FEW_SHOT_EXAMPLES = random.sample(SUPPORT_TICKETS, min(3, len(SUPPORT_TICKETS)))\n",
    "\n",
    "#MODEL SETUP\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "\n",
    "#PROMPT TEMPLATES\n",
    "def zero_shot_prompt(ticket_text):\n",
    "    tags_str = \", \".join(ALL_TAGS)\n",
    "    return f\"\"\"Classify the following support ticket into one of these tags: {tags_str}.\n",
    "Ticket: {ticket_text}\n",
    "Tag:\"\"\"\n",
    "\n",
    "def few_shot_prompt(ticket_text, examples):\n",
    "    tags_str = \", \".join(ALL_TAGS)\n",
    "    prompt = f\"\"\"Classify the following support ticket into one of these tags: {tags_str}.\n",
    "Examples:\n",
    "\"\"\"\n",
    "    for ex in examples:\n",
    "        prompt += f\"Ticket: {ex['text']}\\nTag: {ex['true_tag']}\\n\\n\"\n",
    "    prompt += f\"Ticket: {ticket_text}\\nTag:\"\n",
    "    return prompt\n",
    "\n",
    "#INFERENCE FUNCTION\n",
    "def predict_top_k_tags(prompt, k=3):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=MAX_LENGTH).to(DEVICE)\n",
    "    \n",
    "#Generate multiple outputs using beam search\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=20,\n",
    "        num_beams=NUM_BEAMS * k,\n",
    "        num_return_sequences=k,\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=2,\n",
    "        remove_invalid_values=True\n",
    "    )\n",
    "    \n",
    "#Decode and clean predictions\n",
    "    decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "#Normalize: lowercase, strip, and deduplicate\n",
    "    tags = list(dict.fromkeys([tag.strip().lower() for tag in decoded]))\n",
    "    \n",
    "#Filter to only known tags\n",
    "    valid_tags = [tag for tag in tags if tag in ALL_TAGS]\n",
    "    \n",
    "#If we don't have k valid tags, pad with most common or random (fallback)\n",
    "    while len(valid_tags) < k and len(ALL_TAGS) > 0:\n",
    "        candidate = random.choice(ALL_TAGS)\n",
    "        if candidate not in valid_tags:\n",
    "            valid_tags.append(candidate)\n",
    "    \n",
    "    return valid_tags[:k]\n",
    "\n",
    "#EVALUATION HELPER\n",
    "def evaluate_predictions(true_tags, predicted_tags_list):\n",
    "    \"\"\"\n",
    "    Simple top-1 accuracy: if true tag is in top-k predictions, count as correct.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = len(true_tags)\n",
    "    for true, preds in zip(true_tags, predicted_tags_list):\n",
    "        if true in preds:\n",
    "            correct += 1\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "#MAIN EXECUTION\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸš€ Auto Tagging Support Tickets Using LLM\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "#Store results\n",
    "    zero_shot_predictions = []\n",
    "    few_shot_predictions = []\n",
    "    true_labels = [ticket[\"true_tag\"] for ticket in SUPPORT_TICKETS]\n",
    "\n",
    "    for ticket in SUPPORT_TICKETS:\n",
    "        text = ticket[\"text\"]\n",
    "\n",
    "        #Zero-shot\n",
    "        prompt_zs = zero_shot_prompt(text)\n",
    "        top3_zs = predict_top_k_tags(prompt_zs, k=3)\n",
    "        zero_shot_predictions.append(top3_zs)\n",
    "\n",
    "        #Few-shot\n",
    "        prompt_fs = few_shot_prompt(text, FEW_SHOT_EXAMPLES)\n",
    "        top3_fs = predict_top_k_tags(prompt_fs, k=3)\n",
    "        few_shot_predictions.append(top3_fs)\n",
    "\n",
    "        print(f\"\\nTicket: {text}\")\n",
    "        print(f\"True Tag: {ticket['true_tag']}\")\n",
    "        print(f\"Zero-shot Top-3: {top3_zs}\")\n",
    "        print(f\"Few-shot Top-3:  {top3_fs}\")\n",
    "\n",
    "#Evaluate\n",
    "    acc_zs = evaluate_predictions(true_labels, zero_shot_predictions)\n",
    "    acc_fs = evaluate_predictions(true_labels, few_shot_predictions)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“Š PERFORMANCE COMPARISON\")\n",
    "    print(f\"Zero-shot Top-3 Accuracy: {acc_zs:.2%}\")\n",
    "    print(f\"Few-shot Top-3 Accuracy:  {acc_fs:.2%}\")\n",
    "\n",
    "#FINE-TUNING PLACEHOLDER\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ’¡ Fine-tuning is not implemented in this script.\")\n",
    "    print(\"To implement fine-tuning:\")\n",
    "    print(\"  1. Prepare dataset in 'input: ticket, target: tag' format\")\n",
    "    print(\"  2. Use Hugging Face Trainer with Seq2SeqTrainingArguments\")\n",
    "    print(\"  3. Train model and replace inference model above\")\n",
    "    print(\"Example fine-tuning guide: https://huggingface.co/docs/transformers/training\")\n",
    "\n",
    "    print(\"\\nâœ… Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f70378-0faa-45f7-90be-191bda4dfef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
